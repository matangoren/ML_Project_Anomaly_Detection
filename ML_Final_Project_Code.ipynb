{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Final_Project.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APvI9XHsk2jN"
      },
      "source": [
        "# Outlier Detection for Time Series with Recurrent Autoencoder Ensembles\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3opQBEhk6c0"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgFrdIGiU_3O"
      },
      "source": [
        "# A package for multi input - multi output random search\n",
        "!pip install keras-hypetune"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOC9iTUQk5bU"
      },
      "source": [
        "import os\n",
        "import random\n",
        "from time import time\n",
        "from google.colab import drive\n",
        "from functools import partial\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tqdm.notebook import tqdm\n",
        "from scipy import stats\n",
        "\n",
        "from sklearn.model_selection import KFold, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import auc, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Model, Input, layers\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Bidirectional, LSTM, LSTMCell, GRU, GRUCell, Reshape, Dropout, GaussianNoise, Concatenate, Lambda, RepeatVector, TimeDistributed\n",
        "\n",
        "from kerashypetune import KerasRandomSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWyiZTXxI9te"
      },
      "source": [
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13Y3qgLvwCLL"
      },
      "source": [
        "## Data Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oww_GbXfHFwH"
      },
      "source": [
        "TIME_STEPS = 6\n",
        "\n",
        "# Generated training sequences for use in the model.\n",
        "def create_sequences(values, time_steps=TIME_STEPS, stride=1):\n",
        "    output = []\n",
        "    for i in range(0, len(values) - time_steps, stride):\n",
        "        output.append(values[i : (i + time_steps)])\n",
        "    return np.stack(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQV9Peu6FJFe"
      },
      "source": [
        "## Evaluation Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r959Zd5o0vVW"
      },
      "source": [
        "def _enumerate_thresholds(rec_errors, n=1000):\n",
        "    # maximum value of the anomaly score for all time steps in the test data\n",
        "    thresholds, step_size = [], np.max(rec_errors) / n\n",
        "    th = 0.\n",
        "    # create a uniform threshold values\n",
        "    for i in range(n):\n",
        "        thresholds.append(th)\n",
        "        th = th + step_size\n",
        "    \n",
        "    return thresholds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0j3giH9_0xFc"
      },
      "source": [
        "def _compute_anomaly_scores(x, rec_x, x_val=None, scoring='square_median'):\n",
        "    if scoring == 'absolute':\n",
        "        return np.mean(np.abs(rec_x - x), axis=-1)\n",
        "    elif scoring == 'square_mean':\n",
        "        return np.mean(np.square(rec_x - x), axis=-1)\n",
        "    elif scoring == 'square_median':\n",
        "        # used in the paper\n",
        "        return np.median(np.square(rec_x - x), axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTCXzdpsFNd1"
      },
      "source": [
        "# compute the metrics for the model predictoin\n",
        "def evaluate(x, rec_x, labels, is_reconstructed=True, n=1000, scoring='square_median', x_val=None):\n",
        "    TP, TN, FP, FN = [], [], [], []\n",
        "    precision, f1, tpr, fpr = [], [], [], []\n",
        "    \n",
        "    rec_errors = _compute_anomaly_scores(x, rec_x, scoring) if is_reconstructed else rec_x\n",
        "    if len(rec_errors.shape) > 2:\n",
        "        if scoring.split('_')[1] == 'mean':\n",
        "            rec_errors = np.mean(rec_errors, axis=0)\n",
        "        else:\n",
        "            rec_errors = np.median(rec_errors, axis=0)\n",
        "\n",
        "    # get uniform threshold values    \n",
        "    thresholds = _enumerate_thresholds(rec_errors, n)\n",
        "    \n",
        "    for th in thresholds: # for each threshold\n",
        "        TP_t, TN_t, FP_t, FN_t = 0, 0, 0, 0\n",
        "        for t in range(len(x)): # for each time window\n",
        "            # if any part of the segment has an anomaly, we consider it as anomalous sequence\n",
        "            true_anomalies, pred_anomalies = set(np.where(labels[t] == 1)[0]), set(np.where(rec_errors[t] > th)[0])\n",
        "            if len(pred_anomalies) > 0 and len(pred_anomalies.intersection(true_anomalies)) > 0:\n",
        "                # correct prediction (at least partial overlap with true anomalies)\n",
        "                TP_t = TP_t + 1\n",
        "            elif len(pred_anomalies) == 0 and len(true_anomalies) == 0:\n",
        "                # correct rejection, no predicted anomaly on no true labels\n",
        "                TN_t = TN_t + 1 \n",
        "            elif len(pred_anomalies) > 0 and len(true_anomalies) == 0:\n",
        "                # false alarm (i.e., predict anomalies on no true labels)\n",
        "                FP_t = FP_t + 1\n",
        "            elif len(pred_anomalies) == 0 and len(true_anomalies) > 0:\n",
        "                # predict no anomaly when there is at least one true anomaly within the seq.\n",
        "                FN_t = FN_t + 1\n",
        "        \n",
        "        TP.append(TP_t)\n",
        "        TN.append(TN_t)\n",
        "        FP.append(FP_t)\n",
        "        FN.append(FN_t)\n",
        "    \n",
        "    for i in range(len(thresholds)):\n",
        "        precision.append(TP[i] / (TP[i] + FP[i] + 0.0000001))\n",
        "        tpr.append(TP[i] / (TP[i] + FN[i] + 0.0000001)) # recall or true positive rate (TPR)\n",
        "        fpr.append(FP[i] / (FP[i] + TN[i] + 0.0000001))\n",
        "        f1.append(2 * (precision[i] * tpr[i]) / (precision[i] + tpr[i] + 0.0000001))\n",
        "    \n",
        "    return {\n",
        "        'rec_errors': rec_errors,\n",
        "        'precision': np.mean(precision),\n",
        "        'tpr': np.mean(tpr),\n",
        "        'fpr': np.mean(fpr),\n",
        "        'f1': np.mean(f1),\n",
        "        'pr_auc': auc(tpr, precision),\n",
        "        'roc_auc': auc(fpr, tpr),\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfKhBqKyXCgR"
      },
      "source": [
        "def calculate_accuracy(test_y, rec_errors, threshold=0.5):\n",
        "    prediction, ground_truth = [], []\n",
        "    for t in range(len(test_y)): # for each time window\n",
        "            true_anomalies, pred_anomalies = set(np.where(test_y[t] == 1)[0]), set(np.where(rec_errors[t] > threshold)[0])\n",
        "            if len(pred_anomalies) > 0 and len(pred_anomalies.intersection(true_anomalies)) > 0:\n",
        "                prediction.append(1)\n",
        "                ground_truth.append(1)\n",
        "            elif len(pred_anomalies) == 0 and len(true_anomalies) == 0:\n",
        "                prediction.append(0)\n",
        "                ground_truth.append(0)\n",
        "            elif len(pred_anomalies) > 0 and len(true_anomalies) == 0:\n",
        "                prediction.append(1)\n",
        "                ground_truth.append(0)\n",
        "            elif len(pred_anomalies) == 0 and len(true_anomalies) > 0:\n",
        "                prediction.append(0)\n",
        "                ground_truth.append(1)\n",
        "    return accuracy_score(ground_truth, prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRgjDsiol4Ld"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s82QYs0rcp6w"
      },
      "source": [
        "### LSTM AE - Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udCZ-IP7cvKn"
      },
      "source": [
        "def LSTM_AE(X_train,  param):\n",
        "    LSTM = layers.LSTM\n",
        "    model = keras.Sequential(\n",
        "        [\n",
        "            layers.InputLayer(input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "            LSTM(64, return_sequences=True),\n",
        "            LSTM(32),\n",
        "            layers.RepeatVector(X_train.shape[1]),\n",
        "            LSTM(32, return_sequences=True),\n",
        "            LSTM(64),\n",
        "            layers.Dense(X_train.shape[1] *  X_train.shape[2]),\n",
        "            layers.Reshape([X_train.shape[1], X_train.shape[2]])\n",
        "        ]\n",
        "    )\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=param['learning_rate'], clipnorm=param['clipnorm']), loss=param['loss'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paFKIjn_mBei"
      },
      "source": [
        "### S-RNN - Paper's Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wThnCuvl7or"
      },
      "source": [
        "# baisc S-RNN unit\n",
        "class SkipRNN(tf.keras.layers.Layer):\n",
        "    def __init__(self, cell, return_sequences=False, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.cell = cell\n",
        "        self.return_sequences = return_sequences\n",
        "        self.get_initial_state = getattr(\n",
        "            self.cell, \"get_initial_state\", self.fallback_initial_state)\n",
        "    def fallback_initial_state(self, inputs):\n",
        "        return [tf.zeros([self.cell.state_size], dtype=inputs.dtype)]\n",
        "    @tf.function\n",
        "    def call(self, inputs, states=None):\n",
        "        states = self.get_initial_state(inputs) if states == None else states\n",
        "\n",
        "        outputs = tf.zeros(shape=[self.cell.output_size], dtype=inputs.dtype)\n",
        "        outputs, states = self.cell(inputs, states)\n",
        "\n",
        "        return outputs, states"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe8EKX4rmG9T"
      },
      "source": [
        "def S_RNN(params):\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "    # weight vector - as described in the paper\n",
        "    sparseness_weights = [(0, 1), (1, 0), (1, 1)]\n",
        "    N, N_LAYERS, N_UNITS = 10, 1, 8\n",
        "  \n",
        "    seq_length, dim = params['seq_length'], params['dim']\n",
        "\n",
        "    en_input = Input(shape=[seq_length, dim])\n",
        "    X = GaussianNoise(0.5)(en_input) # add noise to input\n",
        "\n",
        "    # create encoder part and the shared vecotr of the ensemble\n",
        "    shared_latents = []\n",
        "    for i in range(N):\n",
        "        prev_states = []\n",
        "        skip_length = np.random.randint(low=2, high=params['high'], size=1)[0] # random skip size selection\n",
        "        w1, w2 = np.array(sparseness_weights)[np.random.choice(3, size=1)][0] # random weight vector selection\n",
        "        w = w1 + w2\n",
        "\n",
        "        for t in range(seq_length):\n",
        "            Xt = Lambda(lambda x: x[:, t, :])(X)\n",
        "            if t == 0:\n",
        "                O, H = SkipRNN(GRUCell(N_UNITS))(Xt)\n",
        "            else:\n",
        "                if t - skip_length >= 0:\n",
        "                    # apply skip connection\n",
        "                    states = (w1 * prev_states[t-1] + w2 * prev_states[t-skip_length]) / w\n",
        "                    O, H = SkipRNN(GRUCell(N_UNITS))(Xt, states)\n",
        "                else:\n",
        "                    O, H = SkipRNN(GRUCell(N_UNITS))(Xt, prev_states[t-1])\n",
        "\n",
        "            prev_states.append(H)\n",
        "        shared_latents.append(H)\n",
        "\n",
        "    de_outputs = []\n",
        "    de_input = Concatenate()(shared_latents)\n",
        "    D = Dense(dim, kernel_regularizer=tf.keras.regularizers.l1(params['l1']))(de_input)\n",
        "\n",
        "    # create decoder part of the ensemble\n",
        "    for i in range(N):\n",
        "        Y_i = []\n",
        "        prev_states = []\n",
        "        skip_length = np.random.randint(low=2, high=params['high'], size=1)[0]\n",
        "        w1, w2 = np.array(sparseness_weights)[np.random.choice(3, size=1)][0]\n",
        "        w = w1 + w2\n",
        "\n",
        "        for t in range(seq_length):\n",
        "            if t == 0:\n",
        "                y = Dense(dim)(D)\n",
        "                _, H = SkipRNN(GRUCell(dim))(y, D) # y_t\n",
        "            else:\n",
        "                if t - skip_length >= 0:\n",
        "                    # apply skip connection\n",
        "                    states = (w1 * prev_states[t-1] + w2 * prev_states[t-skip_length]) / w\n",
        "                    y, H = SkipRNN(GRUCell(dim))(Y_i[t-1], states)\n",
        "                else:\n",
        "                    y, H = SkipRNN(GRUCell(dim))(Y_i[t-1], prev_states[t-1])\n",
        "\n",
        "            Y_i.append(y)\n",
        "            prev_states.append(H)\n",
        "\n",
        "        # current level autoencoder output\n",
        "        Y_i = Concatenate()(Y_i)\n",
        "        Y_i = Reshape([seq_length, dim])(Y_i) # resize to match original dimensions\n",
        "        de_outputs.append(Y_i)\n",
        "\n",
        "    model = Model(inputs=en_input, outputs=de_outputs)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse')\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjV6cwkumSKy"
      },
      "source": [
        "### LIS-RNN - Linear Incremental S-RNN - Our Improved Version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCVneOmWmYpz"
      },
      "source": [
        "def LIS_RNN(params):\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "    # weight vector as described in the paper\n",
        "    sparseness_weights = [(0, 1), (1, 0), (1, 1)]\n",
        "    N, N_LAYERS, N_UNITS = 10, 1, 8\n",
        "\n",
        "    seq_length, dim = params['seq_length'], params['dim']\n",
        "\n",
        "    en_input = Input(shape=[seq_length, dim])\n",
        "    X = GaussianNoise(0.5)(en_input)\n",
        "\n",
        "    shared_latents = []\n",
        "    for i in range(N):\n",
        "        prev_states = []\n",
        "        skip_length = i+1 # linear skip size selection\n",
        "        w1, w2 = np.array(sparseness_weights)[np.random.choice(3, size=1)][0]\n",
        "        w = w1 + w2\n",
        "\n",
        "        for t in range(seq_length):\n",
        "            Xt = Lambda(lambda x: x[:, t, :])(X)\n",
        "            if t == 0:\n",
        "                O, H = SkipRNN(GRUCell(N_UNITS))(Xt)\n",
        "            else:\n",
        "                if t - skip_length >= 0:\n",
        "                    states = (w1 * prev_states[t-1] + w2 * prev_states[t-skip_length]) / w\n",
        "                    O, H = SkipRNN(GRUCell(N_UNITS))(Xt, states)\n",
        "                else:\n",
        "                    O, H = SkipRNN(GRUCell(N_UNITS))(Xt, prev_states[t-1])\n",
        "\n",
        "            prev_states.append(H)\n",
        "        shared_latents.append(H)\n",
        "\n",
        "    de_outputs = []\n",
        "    de_input = Concatenate()(shared_latents)\n",
        "    # global shared representation\n",
        "    D_shared = Dense(dim, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(params['l1']))(de_input)\n",
        "\n",
        "    for i in range(N):\n",
        "        Y_i = []\n",
        "        prev_states = []\n",
        "        skip_length = i+1 # linear skip size selection\n",
        "        w1, w2 = np.array(sparseness_weights)[np.random.choice(3, size=1)][0]\n",
        "        w = w1 + w2\n",
        "        \n",
        "        # global + specific representation for each level\n",
        "        D_each = Dense(dim, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(params['l1']))(shared_latents[i])\n",
        "\n",
        "        D = Concatenate()([D_shared, D_each])\n",
        "        D = Dense(dim)(D)\n",
        "\n",
        "        for t in range(seq_length):\n",
        "            if t == 0:\n",
        "                y = Dense(dim)(D)\n",
        "                _, H = SkipRNN(GRUCell(dim))(y, D)\n",
        "            else:\n",
        "                if t - skip_length >= 0:\n",
        "                    states = (w1 * prev_states[t-1] + w2 * prev_states[t-skip_length]) / w\n",
        "                    y, H = SkipRNN(GRUCell(dim))(Y_i[t-1], states)\n",
        "                else:\n",
        "                    y, H = SkipRNN(GRUCell(dim))(Y_i[t-1], prev_states[t-1])\n",
        "\n",
        "            Y_i.append(y)\n",
        "            prev_states.append(H)\n",
        "\n",
        "        # current level autoencoder output\n",
        "        Y_i = Concatenate()(Y_i)\n",
        "        Y_i = Reshape([seq_length, dim])(Y_i)\n",
        "        de_outputs.append(Y_i)\n",
        "\n",
        "    model = Model(inputs=en_input, outputs=de_outputs)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=params['loss'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZilHWq6N9n-P"
      },
      "source": [
        "## Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIVQMxq5UCrZ"
      },
      "source": [
        "### LSTM-AE - Baseline Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpvagrJLTdIM"
      },
      "source": [
        "def process_LSTM(name, data_df,label_df, seq_length = 8, stride = 4): \n",
        "    total_scores = {'dataset': [], 'f1': [], 'pr_auc': [], 'roc_auc': [], 'tpr':[], 'fpr':[], 'precision':[], 'accuracy':[], 'training_time(sec)':[], 'Inference_time(sec)':[],'folds_best_params':[]}\n",
        "    kfold = KFold(10, shuffle=True)\n",
        "    for i, (train, test) in enumerate(kfold.split(data_df)):\n",
        "        t1=time()\n",
        "        \n",
        "        train_df = data_df.iloc[train]\n",
        "        test_df = data_df.iloc[test]\n",
        "        train_labels = label_df.iloc[train].values\n",
        "        labels = label_df.iloc[test].values\n",
        "        \n",
        "        scaler = MinMaxScaler()\n",
        "        train_df = scaler.fit_transform(train_df)\n",
        "        test_df = scaler.transform(test_df)\n",
        "        \n",
        "        # creating sequence train and test data\n",
        "        X_train = create_sequences(train_df, time_steps=seq_length, stride=stride)\n",
        "        X_test = create_sequences(test_df, time_steps=seq_length, stride=stride)\n",
        "        \n",
        "        y_train = create_sequences(train_labels, time_steps=seq_length, stride=stride)\n",
        "        y_test = create_sequences(labels, time_steps=seq_length, stride=stride)\n",
        "        \n",
        "        # hyperparameters for the model\n",
        "        param_grid = {\n",
        "            'learning_rate': [0.001, 0.002,0.005, 0.006, 0.007, 0.01, 0.015],\n",
        "            'loss': ['mse','msle','mae','mape',],\n",
        "            'clipnorm': [1,2,2.5]\n",
        "        }\n",
        "        t = time()\n",
        "        cv = KFold(n_splits=3)\n",
        "\n",
        "        # perform random search\n",
        "        krs = KerasRandomSearchCV(partial(LSTM_AE, X_train), param_grid, cv=cv, n_iter=50, sampling_seed=33,\n",
        "                          monitor='val_loss', greater_is_better=False, tuner_verbose=0)\n",
        "\n",
        "        krs.search(X_train, X_train, callbacks=[es], epochs=1)\n",
        "        training_time = round(time()-t,4)\n",
        "\n",
        "        # get best hyperparameters\n",
        "        folds_best_scores = krs.folds_best_score \n",
        "        best_fold_index = min(folds_best_scores, key=folds_best_scores.get)\n",
        "        best_model = krs.folds_best_models[best_fold_index] \n",
        "        folds_best_params = krs.folds_best_params[best_fold_index] \n",
        "        \n",
        "        # inference stage\n",
        "        test_sample = data_df.sample(1000, replace=True)\n",
        "        test_sample = create_sequences(test_sample, time_steps=seq_length, stride=stride)\n",
        "        t = time()\n",
        "        best_model.predict(test_sample)\n",
        "        inference_time = round(time()-t,4)\n",
        "\n",
        "        scores = evaluate(X_test, best_model.predict(X_test),y_test , is_reconstructed=True)# scoring='square_median'\n",
        "\n",
        "        # save current fold results\n",
        "        total_scores['dataset'].append(name)\n",
        "        total_scores['f1'].append(scores['f1'])\n",
        "        total_scores['pr_auc'].append(scores['pr_auc'])\n",
        "        total_scores['roc_auc'].append(scores['roc_auc'])\n",
        "        total_scores['fpr'].append(scores['fpr'])\n",
        "        total_scores['tpr'].append(scores['tpr'])\n",
        "        total_scores['precision'].append(scores['precision'])\n",
        "        total_scores['accuracy'].append(calculate_accuracy(y_test, scores['rec_errors']))\n",
        "        total_scores['training_time(sec)'].append(training_time)\n",
        "        total_scores['Inference_time(sec)'].append(inference_time)\n",
        "        total_scores['folds_best_params'].append(folds_best_params)\n",
        "                \n",
        "    return total_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aj_hVZJ7Jy_6"
      },
      "source": [
        "### S-RNN - Paper's Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAOhI-Qb1LxE"
      },
      "source": [
        "seq_length = 8\n",
        "stride = 4\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\", restore_best_weights=True)#monitor=\"loss\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUclyRt4UuPG"
      },
      "source": [
        "def process_SRNN(name, data_df, label_df, seq_length = 8, stride = 4): \n",
        "    total_scores = {'dataset': [], 'f1': [], 'pr_auc': [], 'roc_auc': [], 'tpr':[], 'fpr':[], 'precision':[], 'accuracy':[], 'training_time(sec)':[],  'Inference_time(sec)':[],'folds_best_params':[]}\n",
        "    kfold = KFold(10, shuffle=True)\n",
        "    for i, (train, test) in enumerate(kfold.split(data_df)):\n",
        "        t1 = time()\n",
        "        \n",
        "        train_df = data_df.iloc[train]\n",
        "        test_df = data_df.iloc[test]\n",
        "        train_labels = label_df.iloc[train].values\n",
        "        labels = label_df.iloc[test].values\n",
        "        \n",
        "        scaler = MinMaxScaler()\n",
        "        train_df = scaler.fit_transform(train_df)\n",
        "        test_df = scaler.transform(test_df)\n",
        "        \n",
        "        # creating sequence train and test data\n",
        "        X_train = create_sequences(train_df, time_steps=seq_length, stride=stride)\n",
        "        X_test = create_sequences(test_df, time_steps=seq_length, stride=stride)\n",
        "        \n",
        "        y_train = create_sequences(train_labels, time_steps=seq_length, stride=stride)\n",
        "        y_test = create_sequences(labels, time_steps=seq_length, stride=stride)\n",
        "        \n",
        "        # hyperparameters for the model\n",
        "        param_grid = {\n",
        "                  'seq_length': X_train.shape[1], \n",
        "                  'dim': X_train.shape[2],\n",
        "                  'high' : [5,7,8,9,10],\n",
        "                  'l1': [0.001, 0.002,0.003,0.004,0.005, 0.006, 0.007, 0.008, 0.009, 0.01],\n",
        "              }\n",
        "\n",
        "        t = time()\n",
        "        cv = KFold(n_splits=3)\n",
        "\n",
        "        # perform random search hyperparameters tuning\n",
        "        kgs = KerasRandomSearchCV(S_RNN, param_grid, cv=cv, n_iter=50, sampling_seed=33, monitor='val_loss', greater_is_better=False, tuner_verbose=0)\n",
        "        kgs.search(X_train, [np.flip(X_train, axis=1) for _ in range(10)], callbacks=[es], epochs=1)\n",
        "        \n",
        "        training_time = round(time()-t,4)\n",
        "\n",
        "        # get best model by score\n",
        "        folds_best_scores = kgs.folds_best_score \n",
        "        best_fold_index = min(folds_best_scores, key=folds_best_scores.get)\n",
        "        best_model = kgs.folds_best_models[best_fold_index] \n",
        "        folds_best_params = kgs.folds_best_params[best_fold_index] \n",
        "\n",
        "        # inference stage\n",
        "        test_sample = data_df.sample(1000, replace=True)\n",
        "        test_sample = create_sequences(test_sample, time_steps=seq_length, stride=stride)\n",
        "        t = time()\n",
        "        best_model.predict(test_sample)\n",
        "        inference_time = round(time()-t,4)\n",
        "\n",
        "        test_seq_rec = [np.flip(rec, axis=1) for rec in best_model.predict(X_test)]\n",
        "        scores = evaluate(X_test, test_seq_rec, y_test, is_reconstructed=True,) #scoring='square_median')\n",
        "\n",
        "        # save current fold results\n",
        "        total_scores['dataset'].append(name)\n",
        "        total_scores['f1'].append(scores['f1'])\n",
        "        total_scores['pr_auc'].append(scores['pr_auc'])\n",
        "        total_scores['roc_auc'].append(scores['roc_auc'])\n",
        "        total_scores['fpr'].append(scores['fpr'])\n",
        "        total_scores['tpr'].append(scores['tpr'])\n",
        "        total_scores['precision'].append(scores['precision'])\n",
        "        total_scores['accuracy'].append(calculate_accuracy(y_test, scores['rec_errors']))\n",
        "        total_scores['training_time(sec)'].append(training_time)\n",
        "        total_scores['Inference_time(sec)'].append(inference_time)\n",
        "        total_scores['folds_best_params'].append(folds_best_params)\n",
        "\n",
        "    return total_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWw43Jakio1p"
      },
      "source": [
        "### LIS-RNN - Our Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYJsT4Ssi0Uk"
      },
      "source": [
        "seq_length = 8\n",
        "stride = 4\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\", restore_best_weights=True)#monitor=\"loss\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag1iY4lyi6sI"
      },
      "source": [
        "# can be merged to one function with process_SRNN - just get the rs hypermodel as a parameter\n",
        "def process_LISRNN(name, data_df, label_df, seq_length = 8, stride = 4): \n",
        "    total_scores = {'dataset': [], 'f1': [], 'pr_auc': [], 'roc_auc': [], 'tpr':[], 'fpr':[], 'precision':[], 'accuracy':[], 'training_time(sec)':[],  'Inference_time(sec)':[],'folds_best_params':[]}\n",
        "    kfold = KFold(10, shuffle=True)\n",
        "    for i, (train, test) in enumerate(kfold.split(data_df)):\n",
        "        print(\"Running fold \" + str(i))\n",
        "        t1 = time()\n",
        "        \n",
        "        train_df = data_df.iloc[train]\n",
        "        test_df = data_df.iloc[test]\n",
        "        train_labels = label_df.iloc[train].values\n",
        "        labels = label_df.iloc[test].values\n",
        "        \n",
        "        scaler = MinMaxScaler()\n",
        "        train_df = scaler.fit_transform(train_df)\n",
        "        test_df = scaler.transform(test_df)\n",
        "        \n",
        "        # create data sequence for the model\n",
        "        X_train = create_sequences(train_df, time_steps=seq_length, stride=stride)\n",
        "        X_test = create_sequences(test_df, time_steps=seq_length, stride=stride)\n",
        "        \n",
        "        y_train = create_sequences(train_labels, time_steps=seq_length, stride=stride)\n",
        "        y_test = create_sequences(labels, time_steps=seq_length, stride=stride)\n",
        "\n",
        "        # hyperparameters for the model\n",
        "        param_grid = {\n",
        "                  'seq_length': X_train.shape[1], \n",
        "                  'dim': X_train.shape[2],\n",
        "                  'loss': ['mse','msle','mae','mape',],\n",
        "                  'l1': [0.001, 0.002, 0.003,0.004,0.005, 0.006, 0.007, 0.008, 0.009, 0.01, 0.015, 0.02, 0.025],\n",
        "              }\n",
        "\n",
        "        t = time()\n",
        "        cv = KFold(n_splits=3)\n",
        "      \n",
        "        # perform random search hyperparameters tuning\n",
        "        kgs = KerasRandomSearchCV(LIS_RNN, param_grid, cv=cv, n_iter=5, sampling_seed=33, monitor='val_loss', greater_is_better=False, tuner_verbose=1)\n",
        "        kgs.search(X_train, [np.flip(X_train, axis=1) for _ in range(10)], callbacks=[es], epochs=1)\n",
        "        \n",
        "        training_time = round(time()-t,2)\n",
        "\n",
        "        # get best model by score\n",
        "        folds_best_scores = kgs.folds_best_score \n",
        "        best_fold_index = min(folds_best_scores, key=folds_best_scores.get)\n",
        "        best_model = kgs.folds_best_models[best_fold_index] \n",
        "        folds_best_params = kgs.folds_best_params[best_fold_index] \n",
        "\n",
        "        # inference stage\n",
        "        test_sample = data_df.sample(1000, replace=True)\n",
        "        test_sample = create_sequences(test_sample, time_steps=seq_length, stride=stride)\n",
        "        t = time()\n",
        "        best_model.predict(test_sample)\n",
        "        inference_time = round(time()-t,4)\n",
        "\n",
        "        test_seq_rec = [np.flip(rec, axis=1) for rec in best_model.predict(X_test)]\n",
        "        scores = evaluate(X_test, test_seq_rec, y_test, is_reconstructed=True, scoring='square_median')\n",
        "\n",
        "        # save current fold results\n",
        "        total_scores['dataset'].append(name)\n",
        "        total_scores['f1'].append(scores['f1'])\n",
        "        total_scores['pr_auc'].append(scores['pr_auc'])\n",
        "        total_scores['roc_auc'].append(scores['roc_auc'])\n",
        "        total_scores['fpr'].append(scores['fpr'])\n",
        "        total_scores['tpr'].append(scores['tpr'])\n",
        "        total_scores['precision'].append(scores['precision'])\n",
        "        total_scores['accuracy'].append(calculate_accuracy(y_test, scores['rec_errors']))\n",
        "        total_scores['training_time(sec)'].append(training_time)\n",
        "        total_scores['Inference_time(sec)'].append(inference_time)\n",
        "        total_scores['folds_best_params'].append(folds_best_params)\n",
        "\n",
        "    return total_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5BTurQfWzB6"
      },
      "source": [
        "# Run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQvPeIcY-tId"
      },
      "source": [
        "For this section we have implemented to type of running methods. The first one, is a regular run, where the code is running sequentially.\n",
        "The second one, is a parallel run, which allowed us to run multiple datasets at once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhS34v4EXAmp"
      },
      "source": [
        "main_data_path = \"/content/drive/MyDrive/ML_Final_Project/dataset_final/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx16sTvFpfR_"
      },
      "source": [
        "## regular\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxnWwplRpjUL"
      },
      "source": [
        "### LSTM run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6-k1fVRSUg5"
      },
      "source": [
        "total_scores =[]\n",
        "\n",
        "dirs = sorted([f for f in os.listdir(main_data_path) if not f.startswith('.')])\n",
        "\n",
        "for dir_ in dirs:\n",
        "    print(dir_)\n",
        "    data_path = main_data_path + dir_\n",
        "    datasets = sorted([f for f in os.listdir(data_path) if os.path.isfile(os.path.join(data_path, f))])\n",
        "    for dataset in tqdm(datasets):\n",
        "        print(dataset)\n",
        "\n",
        "        if dir_ == 'yahoo' or dir_ == 'power':\n",
        "            data_df = pd.read_csv(f'{data_path}/{dataset}')[['value']]\n",
        "            label_df = pd.read_csv(f'{data_path}/{dataset}').iloc[:, -1]\n",
        "\n",
        "        else:\n",
        "            data_df = pd.read_csv(f'{data_path}/{dataset}').iloc[:, 0:-1].astype(float)   \n",
        "            label_df = pd.read_csv(f'{data_path}/{dataset}').iloc[:, -1].astype(int)    \n",
        "\n",
        "\n",
        "        if dir_ == 'ECG':\n",
        "            total_scores.append(process_LSTM(dataset,data_df,label_df, seq_length = 32, stride = 16))\n",
        "        else:\n",
        "            total_scores.append(process_LSTM(dataset,data_df,label_df, seq_length = 16, stride = 4)) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO3VOR4mXkog"
      },
      "source": [
        "res = pd.concat([pd.DataFrame(total_scores[i]) for i in range(len(total_scores))], axis=0)\n",
        "res.to_csv('lstm.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THsXW8yJpnBx"
      },
      "source": [
        "### SRNN Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_o8diuLeCq6"
      },
      "source": [
        "total_scores =[]\n",
        "\n",
        "dirs = sorted([f for f in os.listdir(main_data_path) if not f.startswith('.')])\n",
        "\n",
        "for dir_ in dirs:\n",
        "    print(dir_)\n",
        "    data_path = main_data_path + dir_\n",
        "    datasets = sorted([f for f in os.listdir(data_path) if os.path.isfile(os.path.join(data_path, f))])\n",
        "\n",
        "    for dataset in tqdm(datasets):\n",
        "        print(dataset)\n",
        "\n",
        "        if dir_ == 'yahoo' or dir_ == 'power':\n",
        "            data_df = pd.read_csv(f'{data_path}/{dataset}')[['value']]\n",
        "            label_df = pd.read_csv(f'{data_path}/{dataset}').iloc[:, -1]\n",
        "\n",
        "        else:\n",
        "            data_df = pd.read_csv(f'{data_path}/{dataset}').iloc[:, 0:-1].astype(float)   \n",
        "            label_df = pd.read_csv(f'{data_path}/{dataset}').iloc[:, -1].astype(int)    \n",
        "\n",
        "\n",
        "        if dir_ == 'ECG':\n",
        "            total_scores.append(process_SRNN(dataset,data_df,label_df, seq_length = 32, stride = 16))\n",
        "        else:\n",
        "            total_scores.append(process_SRNN(dataset,data_df,label_df, seq_length = 8, stride = 4)) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP-3bV5Vpshq"
      },
      "source": [
        "res = pd.concat([pd.DataFrame(total_scores[i]) for i in range(len(total_scores))], axis=0)\n",
        "res.to_csv('srnn.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFuoU8rJqGzZ"
      },
      "source": [
        "### LIS-RNN Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B58osXKkqHYS"
      },
      "source": [
        "total_scores =[]\n",
        "\n",
        "dirs = sorted([f for f in os.listdir(main_data_path) if not f.startswith('.')])\n",
        "\n",
        "for dir_ in dirs:\n",
        "    print(dir_)\n",
        "    data_path = main_data_path + dir_\n",
        "    datasets = sorted([f for f in os.listdir(data_path) if os.path.isfile(os.path.join(data_path, f))])\n",
        "\n",
        "    for dataset in tqdm(datasets):\n",
        "        print(dataset)\n",
        "\n",
        "        if dir_ == 'yahoo' or dir_ == 'power':\n",
        "            data_df = pd.read_csv(f'{data_path}/{dataset}')[['value']]\n",
        "            label_df = pd.read_csv(f'{data_path}/{dataset}').iloc[:, -1]\n",
        "\n",
        "        else:\n",
        "            data_df = pd.read_csv(f'{data_path}/{dataset}').iloc[:, 0:-1].astype(float)   \n",
        "            label_df = pd.read_csv(f'{data_path}/{dataset}').iloc[:, -1].astype(int)    \n",
        "\n",
        "\n",
        "        if dir_ == 'ECG':\n",
        "            total_scores.append(process_LISRNN(dataset,data_df,label_df, seq_length = 8, stride = 4))\n",
        "        else:\n",
        "            total_scores.append(process_LISRNN(dataset,data_df,label_df, seq_length = 8, stride = 4)) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT4pZ8BTqMUV"
      },
      "source": [
        "res = pd.concat([pd.DataFrame(total_scores[i]) for i in range(len(total_scores))], axis=0)\n",
        "res.to_csv('lisrnn.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FUNKaWypvv1"
      },
      "source": [
        "## parallel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-MYbBYApyG5"
      },
      "source": [
        "### parallel_LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4CMlbzspuXf"
      },
      "source": [
        "def parallel_LSTM(path): \n",
        "    dir_ = path.split('/')[-2]\n",
        "    if dir_ == 'yahoo' or dir_ == 'power':\n",
        "        data_df = pd.read_csv(path)[['value']]\n",
        "        label_df = pd.read_csv(path).iloc[:, -1]\n",
        "\n",
        "    else:\n",
        "        data_df = pd.read_csv(path).iloc[:, 0:-1].astype(float)   \n",
        "        label_df = pd.read_csv(path).iloc[:, -1].astype(int)    \n",
        "\n",
        "\n",
        "    if dir_ == 'ECG':\n",
        "        return process_LSTM(path.split('/')[-1],data_df,label_df, seq_length = 32, stride = 16)\n",
        "    else:\n",
        "        return process_LSTM(path.split('/')[-1],data_df,label_df, seq_length = 16, stride = 4)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj7aNAkep16P"
      },
      "source": [
        "t = time()\n",
        "files = sorted([root+'/'+files for root,_,f in os.walk(main_data_path)  for files in f ])\n",
        "total_scores_all = Parallel(n_jobs=20)(delayed(parallel_LSTM)(path) for path in files)\n",
        "print(time()-t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbUhuB28p3Pb"
      },
      "source": [
        "res = pd.concat([pd.DataFrame(total_scores_all[i]) for i in range(len(total_scores_all))], axis=0)\n",
        "res.to_csv('lstm.csv')\n",
        "# res.groupby('dataset').mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FU0pkJePp43W"
      },
      "source": [
        "### Parallel S-RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVLba1r8p5Z4"
      },
      "source": [
        "def parallel_SRNN(path): \n",
        "    dir_ = path.split('/')[-2]\n",
        "    if dir_ == 'yahoo' or dir_ == 'power':\n",
        "        data_df = pd.read_csv(path)[['value']]\n",
        "        label_df = pd.read_csv(path).iloc[:, -1]\n",
        "\n",
        "    else:\n",
        "        data_df = pd.read_csv(path).iloc[:, 0:-1].astype(float)   \n",
        "        label_df = pd.read_csv(path).iloc[:, -1].astype(int)    \n",
        "\n",
        "\n",
        "    if dir_ == 'ECG':\n",
        "        return process_SRNN(path.split('/')[-1],data_df,label_df, seq_length = 32, stride = 16)\n",
        "    else:\n",
        "        return process_SRNN(path.split('/')[-1],data_df,label_df, seq_length = 8, stride = 4)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7HxFDL1p9Kc"
      },
      "source": [
        "t = time()\n",
        "files = sorted([root+'/'+files for root,_,f in os.walk(main_data_path)  for files in f ])\n",
        "total_scores_all = Parallel(n_jobs=20)(delayed(parallel_SRNN)(path) for path in files)\n",
        "print(time()-t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btvk4pnxp7H8"
      },
      "source": [
        "res = pd.concat([pd.DataFrame(total_scores_all[i]) for i in range(len(total_scores_all))], axis=0)\n",
        "res.to_csv('srnn.csv')\n",
        "# res.groupby('dataset').mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwekIrUHp_XM"
      },
      "source": [
        "### Parallel LIS-RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sbl8fsCgp-xZ"
      },
      "source": [
        "def parallel_LISRNN(path): \n",
        "    dir_ = path.split('/')[-2]\n",
        "    if dir_ == 'yahoo' or dir_ == 'power':\n",
        "        data_df = pd.read_csv(path)[['value']]\n",
        "        label_df = pd.read_csv(path).iloc[:, -1]\n",
        "\n",
        "    else:\n",
        "        data_df = pd.read_csv(path).iloc[:, 0:-1].astype(float)   \n",
        "        label_df = pd.read_csv(path).iloc[:, -1].astype(int)    \n",
        "\n",
        "\n",
        "    if dir_ == 'ECG':\n",
        "        return process_LISRNN(path.split('/')[-1],data_df,label_df, seq_length = 32, stride = 16)\n",
        "    else:\n",
        "        return process_LISRNN(path.split('/')[-1],data_df,label_df, seq_length = 8, stride = 4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTWIPgZBp-zp"
      },
      "source": [
        "t = time()\n",
        "files = sorted([root+'/'+files for root,_,f in os.walk(main_data_path)  for files in f ])\n",
        "total_scores_all = Parallel(n_jobs=20)(delayed(parallel_LISRNN)(path) for path in files)\n",
        "print(time()-t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MG4cvUMZp-2b"
      },
      "source": [
        "res = pd.concat([pd.DataFrame(total_scores_all[i]) for i in range(len(total_scores_all))], axis=0)\n",
        "res.to_csv('lisrnn.csv')\n",
        "# res.groupby('dataset').mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGW0zk6rLZXC"
      },
      "source": [
        "#Friedman Test & Post Hoc Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emJIVc3uMwI1"
      },
      "source": [
        "!pip install scikit-posthocs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfQOqr-cLfvI"
      },
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import scikit_posthocs as sp\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqbxKGcYLrI5"
      },
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n",
        "results_path = \"/content/drive/MyDrive/ML_Final_Project/Results_final/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Edf5Om5IT7wQ"
      },
      "source": [
        "# get relevant data from result file\n",
        "def get_result_df(filename):\n",
        "  result_df = pd.read_csv(results_path + filename)[['dataset','f1','pr_auc','roc_auc','tpr','fpr','precision','accuracy']]\n",
        "  return result_df.groupby('dataset').mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOGB2LUYSVcC"
      },
      "source": [
        "result_lstm_df = get_result_df(\"lstm.csv\")\n",
        "result_srnn_df = get_result_df(\"srnn.csv\")\n",
        "result_lisrnn_df = get_result_df(\"lisrnn.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UP_YBJ1gUhwz"
      },
      "source": [
        "result_lstm_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNrC_qgieAGL"
      },
      "source": [
        "result_srnn_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VslziE1UUkBi"
      },
      "source": [
        "result_lisrnn_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inRO9dGab4k5"
      },
      "source": [
        "# perform the Friedman test on all of the metrics\n",
        "print(\"tpr: \", stats.friedmanchisquare(result_lstm_df['tpr'], result_srnn_df['tpr'], result_lisrnn_df['tpr']))\n",
        "print(\"fpr: \", stats.friedmanchisquare(result_lstm_df['fpr'], result_srnn_df['fpr'], result_lisrnn_df['fpr']))\n",
        "print(\"precision: \", stats.friedmanchisquare(result_lstm_df['precision'], result_srnn_df['precision'], result_lisrnn_df['precision']))\n",
        "print(\"accuracy: \", stats.friedmanchisquare(result_lstm_df['accuracy'], result_srnn_df['accuracy'], result_lisrnn_df['accuracy']))\n",
        "print(\"roc_auc: \", stats.friedmanchisquare(result_lstm_df['roc_auc'], result_srnn_df['roc_auc'], result_lisrnn_df['roc_auc']))\n",
        "print(\"pr_auc: \", stats.friedmanchisquare(result_lstm_df['pr_auc'], result_srnn_df['pr_auc'], result_lisrnn_df['pr_auc']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4xWzTPm8BKp"
      },
      "source": [
        "### Accuracy Post-hoc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7jd0lHGN-NK"
      },
      "source": [
        "lstm_accuracy = result_lstm_df['accuracy'].values\n",
        "srnn_accuracy = result_srnn_df['accuracy'].values\n",
        "lisrn_accuracy = result_lisrnn_df['accuracy'].values\n",
        "\n",
        "data = np.array([lstm_accuracy, srnn_accuracy, lisrn_accuracy])\n",
        "\n",
        "sp.posthoc_nemenyi_friedman(data.T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeVRVUD48FyG"
      },
      "source": [
        "### Tpr Post-hoc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1wa14qrPHfL"
      },
      "source": [
        "lstm_tpr = result_lstm_df['tpr'].values\n",
        "srnn_tpr = result_srnn_df['tpr'].values\n",
        "lisrn_tpr = result_lisrnn_df['tpr'].values\n",
        "\n",
        "data = np.array([lstm_tpr, srnn_tpr, lisrn_tpr])\n",
        "\n",
        "sp.posthoc_nemenyi_friedman(data.T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWzwZ0FT8Jsg"
      },
      "source": [
        "### Fpr Post-hoc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7RAvUAnPULO"
      },
      "source": [
        "lstm_fpr = result_lstm_df['fpr'].values\n",
        "srnn_fpr = result_srnn_df['fpr'].values\n",
        "lisrn_fpr = result_lisrnn_df['fpr'].values\n",
        "\n",
        "data = np.array([lstm_fpr, srnn_fpr, lisrn_fpr])\n",
        "\n",
        "sp.posthoc_nemenyi_friedman(data.T)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}